# Mitigating annotation shift in cancer classification using single image generative models

```
Marta Buetas Arcas, Richard Osuala, Oliver Díaz, Karim Lekadir (2024). "Mitigating annotation shift in cancer classification using single image generative models." Departament de Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain.
```
## Introduction

## Materials

- For this project, patches were extracted from the mammograms, including both lesion and healthy areas, in both scanned and digital formats. The technique followed for generating the patch dataset is explained in detail in the Python notebook `generate_patch_dataset.ipynb`. To generate the dataset, the [BCDR dataset](https://bcdr.eu/) needs to be downloaded. Three metadata .csv files are also generated, one for lesions, another for healthy digital patches, and a third one for scanned film patches. These files contain the corresponding data required for the study objectives, each with a unique ID for each patch. To convert the previously generated .csv files into a unified .jsonl metadata file, the Python script `csv_to_jsonl_metadata.py` is used. Additionally, the patches containing lesions are extracted with varying percentages of adjacent healthy tissue or different levels of zoom. For the lesions three sets of patches were defined with different levels of zoom, capturing varying percentages of adjacent healthy tissue. Group 1 (G1) patches correspond to the most accurate bounding box defined around the original annotated mask. Group 2 (G2) and 3 (G3) capture patches with double and triple the height and width of the original bounding box, respectively. This approach serves a main purpose: simulating an annotation shift to analyze its influence on the performance of the classifier.

- The research is based on a classification pipeline to distinguish patches from mammograms into three distinct categories: healthy (no lesion), malignant, and benign. To accomplish this task, a pre-trained ResNet50 model, originally trained on the ImageNet dataset, was utilised. This model was obtained from [PyTorch: models and pre-trained weights](https://pytorch.org/vision/stable/models.html). To optimise the training process and focus on fine-tuning the last layer for improved classification performance, only the parameters of the last layer were kept trainable. For the multiclass task, there were finally 6147 trainable parameters. In a previous step, a binary task was designed to classify suspicious/non-suspicious patches. The `binary_pipeline.py` script contains the code required for training and testing the classifier across 3 folds. The obtained test AUC of $0.971 \pm 0.009$ indicates that the model is effective in discriminating between classes and ranking instances. Subssequent experiments extended the task to a multiclass classification, categorizing suspicious patches into benign or malignant lesions. This approach facilitates a thorough analysis of detected abnormalities, aiming to predict biopsy outcomes.

- The remaining scripts in the main folder, with the filename extension `multiclass_pipeline.py`, have been adapted from the binary pipeline to incorporate classification for the three classes. Therefore, it is now a 3-class problem. The main modifications include changing the loss function from Binary Cross Entropy to Categorical Cross Entropy, as well as adjusting the dimensions of the last layer added to the ResNet50 model. Additionally, the option of augmenting the training data with synthetic samples generated from SinGAN models has been introduced. While the number of added samples remains the same across all cases to balance the malignant class, the number of SinGAN models used (i.e., the diversity of the generated samples) varies from 2 to 8. To maintain simplicity and clarity, separate files have been created for each number of SinGAN models used. For example, the file `2SinGANs_multiclass_pipeline.py` includes an option (specified through keyboard input) to augment the training data with synthetic samples generated from 2 SinGAN models. The same principle applies to files with 4SinGAN models, 6 SinGAN models, and 8 SinGAN models.

- The folder `SinGAN` includes all the required files for training a SinGAN model from a specific training image, generating synthetic samples, and validating them through the SiFID metric presented by [Shaham, Dekel, and Michaeli](https://ui.adsabs.harvard.edu/abs/2019arXiv190501164R/abstract). It is a clone of [the official pytorch implementation of the paper: "SinGAN: Learning a Generative Model from a Single Natural Image"](https://github.com/tamarott/SinGAN), with some parameters modified and some additional files for the convenience of the development fo this project. Firstly, the script `input_preprocess.py` was added to preprocess the patches, as it is needed as input for the SinGAN model. Secondly, the script `generating_singan.py` was added to train the desired SinGAN models using the preprocessed patches and generate new images from the trained model. The original `config.py` file was modified to have a pyramid scale factor of 0.8. Therefore, the resolution of the image is reduced by 20% when passing to the next scale. Finally, a new file named `SIFID_evaluation.ipynb` was created to compute the SiFID metric for the generated samples.

